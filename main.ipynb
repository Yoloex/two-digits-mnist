{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wall\\anaconda3\\envs\\ass\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"data/X_train.npy\")\n",
    "X_val = np.load(\"data/X_val.npy\")\n",
    "\n",
    "\n",
    "y_train = np.load(\"data/Y_train.npy\")\n",
    "y_val = np.load(\"data/Y_val.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32) / 255\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32) / 255\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.int64)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "This problem can be framed as a multilabel classification because one image has two labels.\n",
    "\n",
    "So unlike one digit MNIST classification, output layer should have 20 units.\n",
    "\n",
    "CNN-based architecture is used.\n",
    "\n",
    "3 consecutive conv blocks, each with 1 convolutional layer and 1 max pooling layer, are used for feature extraction.\n",
    "\n",
    "As image size is 64 $\\times$ 64, 3 conv layers are enough.\n",
    "\n",
    "Classifier consists of 3 dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = self.conv_module(1, 32)  # 32\n",
    "        self.conv2 = self.conv_module(32, 64)  # 16\n",
    "        self.conv3 = self.conv_module(64, 128)  # 8\n",
    "\n",
    "        self.classifier = self.classification_module(\n",
    "            8 * 8 * 128, 10 * 2\n",
    "        )  # Multi-label\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        y = self.classifier(x)\n",
    "\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def conv_module(in_channels, out_channels):\n",
    "        module = nn.Sequential(\n",
    "            # nn.Conv2d(in_channels, in_channels, 3, 1, 1),\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        return module\n",
    "\n",
    "    @staticmethod\n",
    "    def classification_module(in_features, num_class):\n",
    "        classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Linear(2048, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, num_class),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "        return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "optimizer = Adam(model.parameters(), lr=1e-2)\n",
    "criterion = CrossEntropyLoss()\n",
    "lr_scheduler = OneCycleLR(optimizer, max_lr=1e-2, epochs=epochs, steps_per_epoch=15)\n",
    "metric = MultilabelAccuracy(num_labels=10 * 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 5.613500724585292\n",
      "Val Loss: 5.490601503396336\n",
      "Accuracy on all validation data: 0.9180700182914734\n",
      "--------------------\n",
      "Epoch 2\n",
      "Train Loss: 5.301175937104149\n",
      "Val Loss: 5.28937715216528\n",
      "Accuracy on all validation data: 0.9276624917984009\n",
      "--------------------\n",
      "Epoch 3\n",
      "Train Loss: 5.233660463327036\n",
      "Val Loss: 5.292125732083864\n",
      "Accuracy on all validation data: 0.9308183193206787\n",
      "--------------------\n",
      "Epoch 4\n",
      "Train Loss: 5.212146262391307\n",
      "Val Loss: 5.2530099410045\n",
      "Accuracy on all validation data: 0.9332712888717651\n",
      "--------------------\n",
      "Epoch 5\n",
      "Train Loss: 5.198953593500887\n",
      "Val Loss: 5.246218639084056\n",
      "Accuracy on all validation data: 0.9348629713058472\n",
      "--------------------\n",
      "Epoch 6\n",
      "Train Loss: 5.192322243516818\n",
      "Val Loss: 5.218808807904208\n",
      "Accuracy on all validation data: 0.9363750219345093\n",
      "--------------------\n",
      "Epoch 7\n",
      "Train Loss: 5.185159026624295\n",
      "Val Loss: 5.213337186016614\n",
      "Accuracy on all validation data: 0.9375128746032715\n",
      "--------------------\n",
      "Epoch 8\n",
      "Train Loss: 5.175526906887944\n",
      "Val Loss: 5.193325567849075\n",
      "Accuracy on all validation data: 0.938615083694458\n",
      "--------------------\n",
      "Epoch 9\n",
      "Train Loss: 5.171555872542409\n",
      "Val Loss: 5.190787411943266\n",
      "Accuracy on all validation data: 0.9394755363464355\n",
      "--------------------\n",
      "Epoch 10\n",
      "Train Loss: 5.166525709743317\n",
      "Val Loss: 5.19423248194441\n",
      "Accuracy on all validation data: 0.9401329755783081\n",
      "--------------------\n",
      "Epoch 11\n",
      "Train Loss: 5.165004456005158\n",
      "Val Loss: 5.196889889391163\n",
      "Accuracy on all validation data: 0.9406591653823853\n",
      "--------------------\n",
      "Epoch 12\n",
      "Train Loss: 5.162902952383121\n",
      "Val Loss: 5.190956634811208\n",
      "Accuracy on all validation data: 0.9411300420761108\n",
      "--------------------\n",
      "Epoch 13\n",
      "Train Loss: 5.1602098233402725\n",
      "Val Loss: 5.179670267467257\n",
      "Accuracy on all validation data: 0.9416061639785767\n",
      "--------------------\n",
      "Epoch 14\n",
      "Train Loss: 5.159302437267365\n",
      "Val Loss: 5.180991951423355\n",
      "Accuracy on all validation data: 0.9420057535171509\n",
      "--------------------\n",
      "Epoch 15\n",
      "Train Loss: 5.15650509873899\n",
      "Val Loss: 5.179334604287449\n",
      "Accuracy on all validation data: 0.942353367805481\n",
      "--------------------\n",
      "Epoch 16\n",
      "Train Loss: 5.1551272724383175\n",
      "Val Loss: 5.178965315034118\n",
      "Accuracy on all validation data: 0.9426519274711609\n",
      "--------------------\n",
      "Epoch 17\n",
      "Train Loss: 5.1526727981079885\n",
      "Val Loss: 5.174280794360969\n",
      "Accuracy on all validation data: 0.9429367780685425\n",
      "--------------------\n",
      "Epoch 18\n",
      "Train Loss: 5.149969291382323\n",
      "Val Loss: 5.170979982689966\n",
      "Accuracy on all validation data: 0.9432060718536377\n",
      "--------------------\n",
      "Epoch 19\n",
      "Train Loss: 5.148795994706809\n",
      "Val Loss: 5.174754607526562\n",
      "Accuracy on all validation data: 0.9434239864349365\n",
      "--------------------\n",
      "Epoch 20\n",
      "Train Loss: 5.148019883579339\n",
      "Val Loss: 5.173388239703601\n",
      "Accuracy on all validation data: 0.9436267614364624\n",
      "--------------------\n",
      "Epoch 21\n",
      "Train Loss: 5.147105616121627\n",
      "Val Loss: 5.169477619702303\n",
      "Accuracy on all validation data: 0.9438233375549316\n",
      "--------------------\n",
      "Epoch 22\n",
      "Train Loss: 5.1477298629931365\n",
      "Val Loss: 5.170880390118949\n",
      "Accuracy on all validation data: 0.9439963698387146\n",
      "--------------------\n",
      "Epoch 23\n",
      "Train Loss: 5.146602236043912\n",
      "Val Loss: 5.170849341380445\n",
      "Accuracy on all validation data: 0.9441628456115723\n",
      "--------------------\n",
      "Epoch 24\n",
      "Train Loss: 5.1461987358312635\n",
      "Val Loss: 5.179011809674999\n",
      "Accuracy on all validation data: 0.9442747831344604\n",
      "--------------------\n",
      "Epoch 25\n",
      "Train Loss: 5.147216000115148\n",
      "Val Loss: 5.167773747745948\n",
      "Accuracy on all validation data: 0.9444160461425781\n",
      "--------------------\n",
      "Epoch 26\n",
      "Train Loss: 5.145300395953389\n",
      "Val Loss: 5.167262717138363\n",
      "Accuracy on all validation data: 0.9445509910583496\n",
      "--------------------\n",
      "Epoch 27\n",
      "Train Loss: 5.143430798198469\n",
      "Val Loss: 5.168375751640223\n",
      "Accuracy on all validation data: 0.9446672201156616\n",
      "--------------------\n",
      "Epoch 28\n",
      "Train Loss: 5.142233147788733\n",
      "Val Loss: 5.162249933315229\n",
      "Accuracy on all validation data: 0.9447925090789795\n",
      "--------------------\n",
      "Epoch 29\n",
      "Train Loss: 5.141142942654058\n",
      "Val Loss: 5.160342397569101\n",
      "Accuracy on all validation data: 0.9449148774147034\n",
      "--------------------\n",
      "Epoch 30\n",
      "Train Loss: 5.140824433713675\n",
      "Val Loss: 5.1598510259314425\n",
      "Accuracy on all validation data: 0.9450333118438721\n",
      "--------------------\n",
      "Epoch 31\n",
      "Train Loss: 5.140081964742643\n",
      "Val Loss: 5.158077964299841\n",
      "Accuracy on all validation data: 0.945145308971405\n",
      "--------------------\n",
      "Epoch 32\n",
      "Train Loss: 5.1396391033745426\n",
      "Val Loss: 5.157481235793874\n",
      "Accuracy on all validation data: 0.9452501535415649\n",
      "--------------------\n",
      "Epoch 33\n",
      "Train Loss: 5.1391756146098855\n",
      "Val Loss: 5.158114596258236\n",
      "Accuracy on all validation data: 0.945347011089325\n",
      "--------------------\n",
      "Epoch 34\n",
      "Train Loss: 5.1384495729074695\n",
      "Val Loss: 5.1577818786041645\n",
      "Accuracy on all validation data: 0.9454338550567627\n",
      "--------------------\n",
      "Epoch 35\n",
      "Train Loss: 5.136514378812747\n",
      "Val Loss: 5.160976989359796\n",
      "Accuracy on all validation data: 0.9455037117004395\n",
      "--------------------\n",
      "Epoch 36\n",
      "Train Loss: 5.142145455454866\n",
      "Val Loss: 5.184782390353046\n",
      "Accuracy on all validation data: 0.9455156922340393\n",
      "--------------------\n",
      "Epoch 37\n",
      "Train Loss: 5.139504187404158\n",
      "Val Loss: 5.155859615229353\n",
      "Accuracy on all validation data: 0.9455854296684265\n",
      "--------------------\n",
      "Epoch 38\n",
      "Train Loss: 5.134595822221555\n",
      "Val Loss: 5.15229942828794\n",
      "Accuracy on all validation data: 0.9456583261489868\n",
      "--------------------\n",
      "Epoch 39\n",
      "Train Loss: 5.132623832446699\n",
      "Val Loss: 5.151266997373557\n",
      "Accuracy on all validation data: 0.9457270503044128\n",
      "--------------------\n",
      "Epoch 40\n",
      "Train Loss: 5.131225978985381\n",
      "Val Loss: 5.147887248027174\n",
      "Accuracy on all validation data: 0.9457978010177612\n",
      "--------------------\n",
      "Epoch 41\n",
      "Train Loss: 5.129940157881179\n",
      "Val Loss: 5.14690998536122\n",
      "Accuracy on all validation data: 0.9458654522895813\n",
      "--------------------\n",
      "Epoch 42\n",
      "Train Loss: 5.129025840149901\n",
      "Val Loss: 5.1463583149487455\n",
      "Accuracy on all validation data: 0.9459280371665955\n",
      "--------------------\n",
      "Epoch 43\n",
      "Train Loss: 5.1285178379509775\n",
      "Val Loss: 5.145807610282415\n",
      "Accuracy on all validation data: 0.945991039276123\n",
      "--------------------\n",
      "Epoch 44\n",
      "Train Loss: 5.12801681768399\n",
      "Val Loss: 5.14485756354996\n",
      "Accuracy on all validation data: 0.9460505247116089\n",
      "--------------------\n",
      "Epoch 45\n",
      "Train Loss: 5.127430327784139\n",
      "Val Loss: 5.143581867218018\n",
      "Accuracy on all validation data: 0.9461113810539246\n",
      "--------------------\n",
      "Epoch 46\n",
      "Train Loss: 5.126930200253812\n",
      "Val Loss: 5.143802298775202\n",
      "Accuracy on all validation data: 0.9461679458618164\n",
      "--------------------\n",
      "Epoch 47\n",
      "Train Loss: 5.126355312883663\n",
      "Val Loss: 5.142323590532134\n",
      "Accuracy on all validation data: 0.9462233185768127\n",
      "--------------------\n",
      "Epoch 48\n",
      "Train Loss: 5.12601576826443\n",
      "Val Loss: 5.142422899415221\n",
      "Accuracy on all validation data: 0.9462769627571106\n",
      "--------------------\n",
      "Epoch 49\n",
      "Train Loss: 5.125098932284517\n",
      "Val Loss: 5.141062483002868\n",
      "Accuracy on all validation data: 0.9463266730308533\n",
      "--------------------\n",
      "Epoch 50\n",
      "Train Loss: 5.124885575839887\n",
      "Val Loss: 5.141643819929678\n",
      "Accuracy on all validation data: 0.9463729858398438\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for data, labels in train_loader:\n",
    "        data = data.to(device).unsqueeze(1)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        first_digit_onehot = F.one_hot(labels[:, 0], num_classes=10)\n",
    "        second_digit_onehot = F.one_hot(labels[:, 1], num_classes=10)\n",
    "        one_hot_labels = torch.cat(\n",
    "            (first_digit_onehot, second_digit_onehot), dim=1\n",
    "        ).to(torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(data)\n",
    "\n",
    "        loss = criterion(out, one_hot_labels)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch > 0:\n",
    "        print(\"-\" * 20)\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"Train Loss: {train_loss / len(train_loader)}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for data, labels in val_loader:\n",
    "            data = data.to(device).unsqueeze(1)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            first_digit_onehot = F.one_hot(labels[:, 0], num_classes=10)\n",
    "            second_digit_onehot = F.one_hot(labels[:, 1], num_classes=10)\n",
    "            one_hot_labels = torch.cat(\n",
    "                (first_digit_onehot, second_digit_onehot), dim=1\n",
    "            ).to(torch.float32)\n",
    "\n",
    "            out = model(data)\n",
    "            loss = criterion(out, one_hot_labels)\n",
    "\n",
    "            metric.update(out, one_hot_labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        print(f\"Val Loss: {val_loss / len(val_loader)}\")\n",
    "\n",
    "        print(f\"Accuracy on all validation data: {metric.compute().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
